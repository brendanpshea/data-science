# Data Science: A Practical and Philosophical Introduction
### Brendan Shea, PHD

This virtual textbook (delivered as a series of Jupyter notebooks) provides an introduction to basic concepts and tools of data science. We look both at the technical aspects (using Python, R, and SQL) of data science, and more scientific/philosophical issues regarding methodology, interpretation and communication of results, and ethics.

## [Chapter 1: Introduction to Data Science](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_01_Introduction.ipynb)

In this chapter, you will embark on your journey into the realm of **data science. You will learn about its interdisciplinary nature, combining elements of statistics, mathematics, computer science, and domain-specific knowledge to extract meaningful insights from data. This chapter introduces the crucial role of statistical methods in understanding and predicting patterns, the importance of programming skills for data manipulation and analysis, and the significance of domain expertise for meaningful application of data science. By the end of this chapter, you will grasp the foundational concepts that underpin data science and appreciate its potential in solving real-world problems.

## [Chapter 2: Data Manipulation with Pandas](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_02_Pandas.ipynb)

In this chapter, you will delve into the practical aspects of data manipulation using **Python** and **Pandas**, building on the foundational knowledge acquired in the first chapter. You will learn advanced techniques for filtering, sorting, and transforming datasets, specifically through the exploration of the mtcars dataset, which provides a diverse range of features for analysis. This chapter emphasizes the importance of understanding algorithms—the core of many operations in Pandas—and how they guide data manipulation processes. Beyond the technical aspects, you will engage with the philosophical implications of algorithmic processing, including the potential risks of biases and the ethical considerations in data science. By the end of this chapter, you will have a comprehensive understanding of data manipulation methods, the significance of algorithms, and an appreciation of the ethical dimensions in the field of data science.

## [Chapter 3: Exploratory Data Analysis on the Titanic](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_03_EDA_Titanic.ipynb)

In this chapter, you will learn about the essential step of **exploratory data analysis (EDA)**, a cornerstone of any data science project. EDA helps in understanding and making informed decisions about the data you are working with. You will tackle common challenges encountered in real-world data, such as handling missing data, outliers, and inconsistent entries, using the Titanic dataset. This dataset, containing passenger information from the Titanic ship, will serve as a practical example to apply various techniques for data cleaning and analysis. In addition to acquiring these practical skills, the chapter also delves into the philosophical side of data science, discussing the "problem of induction." This philosophical issue pertains to the challenges of making general predictions based on specific observations, a frequent scenario in data science. By the end of this chapter, you will have not only improved your technical skills in preparing datasets for analysis but also gained insight into the philosophical underpinnings of data science.

## [Chapter 4: Communicating With Stakeholders](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_04_StakeholderCommunication.ipynb)

This chapter introduces you to a critical yet often overlooked aspect of data science: communication with **stakeholders**. As a data scientist, you must be able to convey complex information to a diverse audience, including politicians, generals, doctors, and the general public. The chapter emphasizes the importance of translating data into actionable insights, akin to turning a complex musical composition into a universally understandable melody. You will explore the historical example of **Florence Nightingale's** work during the Crimean War, highlighting how she transformed data into powerful narratives and strategic decisions. This chapter offers insights into the nuances of exploratory data analysis, addressing biases and heuristics, choosing effective visualizations, and constructing compelling reports and dashboards. As a junior data scientist, you will learn the art of communicating complex data to various stakeholders, reinforcing the notion that the ability to tell the story behind the numbers is as vital as any algorithm or statistical model. This chapter is not just a historical lesson but a gateway to understanding the essential role of communication in modern data science, where you become the voice that brings data to life.

## [Chapter 5: Mastering Statistics With MI6](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_05_BasicStats.ipynb)

This chapter takes you on an imaginative journey into the world of statistics, framed within the context of a secret agent role at MI6. You will learn that **statistics** is not just a branch of mathematics dealing with data analysis but a fundamental tool in various real-world applications, including data security analysis. Through the lens of a data security analyst, you will explore how statistics are used to make sense of large volumes of information and uncover patterns indicative of potential threats. This chapter emphasizes the role of statistics as the heart of data science, vital for extracting insights from data. You will engage with statistical methods to analyze metadata, identifying outliers and patterns that could signify critical information. This chapter is designed to showcase the practical application of statistics in a captivating narrative, preparing you to tackle the challenges of data analysis with the skillset of a data scientist and the intrigue of a secret agent.

## [Chapter 6: Aggregate Functions and Data Collection Methods](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_06_AggregateFunctions.ipynb)

This chapter introduces you to the concept of **aggregate functions** in data science. Aggregate functions are essential tools that allow you to create new values by processing collections of existing data. You will learn how to use functions like count, sum, and average to derive meaningful insights from data. This chapter also delves into important **data collection methods**, such as web scraping, accessing public databases, and utilizing APIs (Application Programming Interfaces). Understanding these methods is crucial for gathering the data you need for analysis. By mastering both aggregate functions and data collection techniques, you will enhance your ability to handle, process, and analyze large datasets effectively, equipping you with essential skills for any data-driven project.

## [Chapter 7: Inferential Statistics](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_06_AggregateFunctions.ipynb)

In this chapter, you will delve into the intriguing world of **inferential statistics**, a key component of data science that allows for making inductive inferences beyond the immediate data. You will explore this concept through the lens of the Baumann experiment, a controlled study that investigated the impact of different teaching methods on fourth-grade students' reading comprehension. The chapter illustrates how inferential statistics are used to draw conclusions from experimental data, as demonstrated by the study's findings on the effectiveness of various reading strategies. By understanding and applying the principles of inferential statistics, you will gain the ability to make broader generalizations from specific datasets. This chapter not only equips you with technical skills but also encourages you to think critically about the implications of statistical inferences in real-world scenarios, thereby enhancing your analytical and interpretive capacities as a budding data scientist.

## [Chapter 8: Data Visualization With Zelda and Link](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_08_DataViz.ipynb)

This chapter introduces you to the vital skill of **data visualization**, essential for transforming complex datasets into comprehensible visual formats like graphs and charts. You will learn that data visualization serves as a puzzle-solving tool, piecing together disparate data bits to reveal a more comprehensive picture. The chapter likens data visualization to a treasure map, guiding you through the intricacies of data and helping you uncover hidden patterns, trends, and insights. It emphasizes the human brain's proficiency in visual understanding, illustrating how well-crafted visualizations can expedite the comprehension of complex information. This ability to quickly grasp and interpret visual data is crucial for effective decision-making. The chapter utilizes engaging, fictional examples based on the "Zelda" video games to explain basic concepts of data visualization. These examples are designed to prepare you for applying these visualization techniques to more complex real-world data in subsequent chapters. By mastering data visualization, you will gain a powerful tool to illuminate the dark caves of data analysis, making it easier to navigate and understand the crucial details within your datasets.

## [Chapter 9: Advanced Visualization: Big Five Data](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_09_Big5_CaseStudy.ipynb)

In this chapter, you will advance your understanding of data visualization through the exploration of the Big Five Inventory (BFI) dataset, which examines five major personality traits: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. You will learn to create various types of plots using the Matplotlib library, from simple scatter plots to intricate histograms, and understand how to enhance these visualizations with labels and colors for clarity and effectiveness. This hands-on experience with real-world data will also introduce you to the concept of "data dictionaries," which are vital for comprehending the meaning and structure of data sets. Beyond technical proficiency, this chapter delves into the philosophical debate of realism versus instrumentalism in data representation. You will be encouraged to contemplate whether visualizations are true reflections of reality or merely practical tools. This chapter offers both a practical approach to advanced data visualization techniques and a thoughtful exploration of the philosophical implications of representing information visually. By the end of this chapter, you will not only have developed valuable skills applicable across various fields but also engaged in deeper reflections on the meaning and impact of those skills.

## [Chapter 10: Databases and SQL](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_10_DatabaseSQL.ipynb)

In this chapter, you will explore the fundamental concept of relational databases, a cornerstone of effective data management. You will learn how relational databases, comprising interrelated tables or relations, go beyond the two-dimensional structure of data frames, allowing for efficient organization, retrieval, and manipulation of complex datasets. This chapter introduces you to the multidimensional nature of relational databases, where relationships between tables are defined using keys, enabling you to handle datasets where interrelations between data points are crucial. Through a practical case study set in the world of Jurassic Park, you will understand the application of relational databases in a dynamic and complex environment. This case study involves managing data about various entities like dinosaurs, enclosures, and park staff, highlighting how relational databases can seamlessly handle queries and manage relationships between different data entities. By the end of this chapter, you will have gained both practical skills in SQL and a deeper appreciation of the power and flexibility of relational databases in data science.

## [Chapter 11: Introduction to R for Data Science](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_11_R.ipynb)

In this chapter, you will be introduced to R, a programming language and environment specifically tailored for statistical computing and graphics. Widely utilized by statisticians and data analysts, R offers an extensive array of libraries and built-in functions for intricate data analysis and graphical models. This chapter contrasts R with Python, highlighting R's statistical roots and its sophisticated capabilities in statistical modeling and visualization, particularly through packages like ggplot2. You will explore the differences in design philosophies, community composition, and syntax between R and Python, gaining insight into the unique strengths of R in the realm of data science. By the end of this chapter, you will not only have a foundational understanding of R's capabilities in data analysis but also appreciate its role alongside Python in the broader context of data science.


## [Chapter 12: Introduction to Linear Regression](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_12_LinearRegression.ipynb)
In this chapter, you will be introduced to Linear Regression, a fundamental technique in data science and statistics, using the real-world example of the Boston Housing Dataset. This dataset, rich in details about various houses in Boston, serves as a practical tool for understanding the relationship between house features and their prices. You will learn to predict house prices based on variables such as the number of rooms, age, and crime rate.  The chapter begins by loading and exploring the Boston Housing Data. You will delve into **Linear Regression**, a method used to model the relationship between a dependent variable (house price) and one or more independent variables (house features), and learn how to create, fit, and interpret these models using Python's StatsModel library.  Key concepts covered include R-squared values for assessing model fit, coefficients for understanding variable impact, and p-values for gauging statistical significance. The chapter also extends into multiple regression and concludes with a critical case study on racial bias, examining how such biases can manifest in datasets and affect analysis. By the end of this chapter, you will not only comprehend the mechanics of linear regression but also be equipped to apply these techniques to real-world data, while being mindful of the ethical implications and potential biases inherent in data science.


## [Final Project in Data Science](https://colab.research.google.com/github/brendanpshea/data-science/blob/main/Data_Science_Final_Project.ipynb)
In this chapter, you will apply your accumulated knowledge in a comprehensive final project, encapsulating the essence of data science exploration. You will begin by selecting and loading a dataset from the pydataset library, considering factors like size, complexity, and personal interest. The chapter guides you through the process of investigating the dataset's origin, purpose, and context, emphasizing the importance of understanding the data for meaningful analysis. You will then analyze the dataset's structure, examining variables, dimensionality, and statistical summaries, to inform your analytical approach. This chapter serves as a culmination of your learning journey, where you will employ various data science techniques and tools to conduct a thorough analysis of your chosen dataset. By the end of this project, you will have demonstrated your ability to apply data science concepts in a real-world context, showcasing your skills in data manipulation, analysis, and interpretation.

# Computing Concepts With Python
### Brendan Shea, PhD | Brendan.Shea@rctc.edu
Embark on an engaging journey into the world of computing with "Computing Concepts with Python," an interactive textbook designed to make learning Python and fundamental computing concepts not just informative but genuinely enjoyable. Whether you're a complete beginner or looking to deepen your understanding, this textbook offers a hands-on approach to learning. Through a series of well-crafted Jupyter notebooks, you'll explore everything from the basics of Python programming to the intricacies of artificial intelligence, cybersecurity, and data management. Each chapter is packed with interactive elements that allow you to experiment, code, and immediately see the results of your work. This isn't just a textbook; it's a dynamic learning experience that adapts to your pace and style.

"Computing Concepts with Python" is a resource that transforms the teaching landscape. As an Open Educational Resource, it is freely accessible, allowing you to integrate it seamlessly into your curriculum. Each chapter is meticulously structured to provide comprehensive coverage of key computing topics while encouraging active learning. The interactive notebooks are perfect for classroom demonstrations, homework assignments, or as a foundation for more advanced projects. With this textbook, you're not just providing information; you're offering an immersive educational tool that sparks curiosity, fosters critical thinking, and prepares students for the challenges of the modern technological world.

If you've never used Google Colab before, I think you'll find it's pretty intutive. I've put together a tutorial here: [Ch 0: Brendan's Colab Tutorial](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_00_Intro_to_Colab.ipynb).


### [Ch 1: Computers and Hardware](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_01_ComputersHardware.ipynb)
 This chapter welcomes students to the study of computer science, emphasizing the interactive lecture notes as the class's primary resource. It offers an introductory lecture on computer hardware, aiming to provide an understanding of the physical components of computers. The chapter covers topics such as processors, memory, storage devices, and input/output mechanisms. It emphasizes the importance of understanding computer hardware as the foundation for software interactions and computational tasks.

### [Ch 2: Files and Formats](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_02_Files_and_Formats.ipynb)
This chapter dives into the concept of digital files and formats, using engaging examples like digital artwork, reports, and music recordings to explain the necessity of files as a digital home for various data types. The focus is on understanding the different file types and formats, their specific uses, and the importance of choosing the right format for different kinds of data. This chapter is crucial for grasping how data is stored, accessed, and shared in the digital world.

### [Ch 3: Computer Networking](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_03_Networks.ipynb)
This chapter introduces the concept of computer networking, defining a network as a collection of interconnected devices capable of communication. It covers a range of devices, from traditional computers and smartphones to IoT devices like smart fridges. The focus is on the role of networks in facilitating data and resource sharing, making processes more efficient and collaborative. The chapter explores different types of networks, network protocols, and the practical aspects of using networks for data transmission.

### [Ch 4: Intro to Python: Strings](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_04_IntroToPython_Strings.ipynb)
This chapter introduces students to Python as a programming language, drawing an analogy to human languages to explain its purpose and use. The focus of the chapter is on strings, a fundamental data type in Python, exploring how they are used and manipulated within the language.

### [Ch 5: Data Types and Functions](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_05_IntsFloatsFunctions.ipynb)
This chapter delves into data types and functions in Python, emphasizing their role as foundational elements in programming. It aims to familiarize students with different data types, particularly integers and floating-point numbers, and how these types organize and manage information in code. The chapter introduces the concept of functions, explaining how they are used to perform specific tasks and handle data in Python.

### [Ch 6: Conditionals and Levels of Abstraction](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_06_Conditionals.ipynb)
 Focusing on conditionals and program flow control, this chapter introduces students to the concept of 'abstraction' in computer science. It discusses how conditionals, such as 'if', 'else', and 'elif' statements, are used to direct the execution flow of a program based on specific conditions. The chapter explores various examples and scenarios where conditionals are crucial in decision-making processes within programs.

### [Ch 7: Algorithms and Loops](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_07_Algorithms_and_Loops.ipynb)
This chapter introduces the concept of algorithms as step-by-step procedures or rules for solving problems and accomplishing tasks, both in everyday life and computing. It highlights the importance of algorithms as the foundation of computer programs and applications, and how they are used in various decision-making processes. The chapter likely covers different types of algorithms and introduces loops as a means to execute repetitive tasks efficiently in programming.

### [Ch 08: Cybersecurity](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_08_CyberSecurity.ipynb)
 Addressing the critical importance of cybersecurity in the digital age, this chapter delves into the need to protect digital assets and personal information. It provides an overview of key cybersecurity concepts, real-world examples, and simple Python examples where applicable. The chapter is designed to raise awareness and understanding of cybersecurity threats and measures, making it relevant for students in today's technology-reliant world.

### [Ch 09: An Intro to Data and Databases](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_09_Data_and_Databases.ipynb)
This chapter deals with the vast and crucial world of data and databases. It explains the concept of data, its various types, and its critical role in computer science and decision-making across different fields. The chapter introduces databases as tools for efficiently storing, managing, and retrieving data, underlining their significance in handling the ever-growing volume of digital information.

### [Ch 10: From Data Structures to Software Engineering](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_10_DictionariesObjectsTests.ipynb)
This chapter transitions students into more advanced topics, starting with Python dictionaries, a versatile data structure. It then explores object-oriented programming by introducing objects, a crucial concept in modern software development. The chapter also covers the art of testing code, emphasizing the importance of this practice for ensuring code reliability and functionality. Additionally, it touches upon fundamental software engineering methodologies, providing a comprehensive overview of these key areas in computer science.

### [Chapter 11: Artificial Intelligence (AI)](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_11_ArtificialIntelligence.ipynb)
This a pivotal area of computer science focused on creating machines that can simulate human intelligence. This chapter dives into the core aspects of AI, including learning, reasoning, and self-correction. Students will explore the development of AI through examples like chess-playing programs and natural language processing (NLP) systems. The chapter differentiates between **narrow AI**, designed for specific tasks such as facial recognition, and **general AI**, which mimics human-level intelligence across various domains. It also covers subfields like machine learning and deep learning, illustrating how AI is a rapidly evolving field. This chapter provides a comprehensive overview of AI's history, current applications, and its potential future developments.

### [Chapter 12: Applied AI](https://colab.research.google.com/github/brendanpshea/computing_concepts_python/blob/main/IntroCS_12_AppliedAI.ipynb)
Chapter 12, "Applied AI," introduces students to practical applications of artificial intelligence, specifically focusing on the development of a chatbot inspired by the television series "Futurama." The chapter begins by guiding students through the creation of a simple chatbot, explaining key programming concepts such as string manipulation and regular expressions. It then delves into more advanced features, including pattern matching and using regular expressions to handle user inputs. Students then learn about image manipulation with OpenCV, and the use of generative AI for programming.  This chapter is an excellent demonstration of how AI can be creatively applied, offering an engaging and practical approach to understanding and implementing AI concepts. Students will not only learn the technical skills required for AI development but also appreciate the versatility and creativity involved in AI applications. ​

**A Note on the Use of AI Tools.** These chapters were intitially developed as the “generative AI” explosion took off (staring with OpenAI’s GPT 3.0), and I’ve had fun experimenting with many of these tools—including successive versions of ChatGPT, Google Bard, Claude, Codey, CoPilot, and others—in helping to turn my (voluminous, but often unorganized) lecture notes into something resembling a proper book. My experience was these tools with these has been generally positive, and I think that they can someday do at least some of the work done by traditional editors and publishing houses (I say this as a former editor at an academic press!). I’m less convinced they are going to immediately replace the actual *writer* or *programmer*, though, as there’s still a fair amount of expertise (and effort!) into producing quality, meaningful output.
